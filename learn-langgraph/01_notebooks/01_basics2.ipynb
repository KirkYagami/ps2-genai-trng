{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a682661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9a0277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1dcffe8ea10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Define the State object\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Step 2: Start the Graph Builder with this State class\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Step 3: Create a Node\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "def chatbot_node(old_state: State) -> State:\n",
    "    response = llm.invoke(old_state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "# Step 4: Create Edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bd2ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAAAXNSR0IArs4c6QAAFo5JREFUeJztnXl8E2XewJ/JJGnOJm2a0jP0skBLwZIeHFY5yuECIsdyo+y+vCyg+KKrLOiKCop8VhDUVY5FXF63iCvLWZCir7CUu0BbhNKW3vRu0ua+Zibz/hG3djHJpH2SNu0+37+aeWYmv3z7zMwzzzPz/DCapgGip7D6OoD+DdIHBdIHBdIHBdIHBdIHBRty++Yai1FHWYyUxURRRP9oA+EcjCfAeUJcJMEHDebB7ArrWbuv+q6x6q6x8o5BLGUHBnN4QpwnZHG4/aMuEza7xWg3GymdmjBqyfiRorjhwphkYQ921W19rQ+tF75pJaz2IWmBCY+LpHJOD77Vf9C0EQ8K9WU39QF81vhfh8qjArq1eTf0UQR98Whbbakpc1rwsMzAHkXrv9y7qrtxVh2XInpqntzzrTzVZzZQp/Y1DhrMe2puN/bev6AI+uKxNlWDdcZ/R/BFuCebeKRP3WQ7uafh8fFBqROk3ojTr7n1fcedS9pZqyKCw7iMKzPrM2rJw9sfZs0OSRwl9l6Qfk3ZTf2VXNX8VxTCQIY6yHCtJG32k3sbR2RJ/nPcAQCGpImTx0hO7WugSIa6xaDv+tl2qZyTPiXYq+H1AzKmBouk7Bt57e5Xc6dPqyJKC/TZS8K8HVv/YMrSsPs3dPoO0s067vRdOq5KnxLM4WI+iK0fwOWxRk0Iyj/e5mYdl/q0KkLVZE0ZJ/FNbP2DEVnSllqrmwroUt+DQkPKOAnWP27DfAULBynjJA8K9S5XcFVQUawfPKwnt4EwjB8/vrm5ubtbHT58ePPmzb6JCAweJqgoMrgqda7PoCHNekoWztxu9CL19fUGg8tA3VBSUuKDcH5CHhWgayddHb/OO6yaaizdvXn2HJqmc3Jyzpw5U1tbGx8fP3r06FWrVt26dWv16tUAgBkzZowfP3779u0VFRVHjhwpKChobm6Oj4+fO3furFmzAADl5eWLFy/+6KOP3nnnndDQUD6fX1hYCAA4efLkoUOHEhMTvR5waFRA60OrOMiJK+f6rEaKL4btCnRFTk7OwYMHly9fHh8f39jY+Omnn0okkiVLluzcufPll1/Ozc0NCwsDAOzYsaOlpWXjxo0YhlVWVm7ZskWhUKSmpnK5XADA/v37f/Ob34wcOTIpKem5555LSEjYtGmTjwLmi3GriXJa5EKf2S7w7J65BxQVFQ0fPnzJkiWOj2lpaTab7Zerbdu2zWQyhYeHO9Y5duzY5cuXU1NTHaVjx45dtGiRjyJ8BL4It5rtTouc67PbaZzjq+ZeSkrK7t27t2zZolQqs7KyFAqFixjsOTk5V65cqaurcyxJSkrqLB02bJiPwvslHC7L1d2bc318Ia5qclIjvMLSpUvFYvH58+c3bdrEZrOffvrpl156KSgoqOs6FEWtXbuWpum1a9dmZGQIhcKlS5c6ijAMAwDweFCd7N3CpCdDo51/nXN9AjHbVG7yUTQ4js+ZM2fOnDmVlZU3btzYu3evxWJ5//33u65TUlJSWlq6d+9epVLpWNJ5Ue79p0pMOkogdn4qc1H7xLhZ7/xkCU9ubm5ycnJsbGx8fHx8fLxarf7+++87q5UDvV4PAJDLf+qaLSsrq6+v7zzxPULXDX2BUU8KAp2Lct7uk0cGqBqsdson/+fc3Nz169fn5+frdLr8/PyLFy+OGDECABAVFQUAOHfu3L179+Li4jAMy8nJMRgMVVVVH330UWZmZlNTk9MdRkZG3r179+bNmx0dHV6PliRoTSvhsglMu+DE7obKOwZXpTA0NTW98sorSqVSqVROnTp13759ZrPZUfTGG29kZmauWrWKpumzZ8/OmzdPqVTOmTOnpKTku+++UyqVixYtqq6uViqVBQUFnTssKCiYPXt2RkbGjRs3vB5tRZH+1L4GV6Uue5vvXtY2VlmmLBvk9f9n/yLvf5ujEwVJo50Pjbm8501Uih+Wm9z3dg149B1k/QPzY6572t2NdRRf1DRWWZ5e7ry7tKGhobPp+wgsFstud97OnD9//po1azyIvCesW7euqKjIaZFUKtVoNE6L3nvvvXHjxjktOnOgKeoxwYgsl7127vTZKfC3rTXjZsnjRzjperHb7Uaj0emGFovFVbuMw+H4rslmMpkoynmDgSAIDsf5iD6fz2eznVxYy2/pr55RP/dGjLteO/cnztaHln2vV7Y327x+SvZzVI3Wfa9Xtj60uF+NoTtUHhUwZWnY6c8bbRbnB+OAxGaxn97f+PTycMZuJ4+Gyctu6YsuaGasiBBKfNWP4D8YNOTpz5tSJ0g9GZv19CGNhkrz+a9bpywNC1X4qh/QH2its+Z92Zy9eFB4rEcn6G48IqRrJ0/ta4hNFmVMDWYPuOE3wkZf/1b9sMw0fUVEYLCnfZ3de0CNIuiS67qyW/rhYyXxI0ScgIEgkbDaK4oN967qkjIDXTWPXdHDxyOr7hqrfzQaNIQsPEAkZfOEOE+I95cRYcJGW4yUxUgZNKSqySoO4sSlCGN75/HIR2iqtrQ327QqQtNms5i8fHVWq9UAAJlM5t3d8oQsaQhXIufIwrhhMX3xcG7vsHfvXgzDVq5c2deBuOQ/exgcGqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCn98LWb69OkURdE0bTabAQBCoZCiKA6Hc/r06b4O7VF8NU0aDOHh4YWFhZ2T2zhesU9LS+vruJzgjwfvwoULpdJ/m55cJpN1zmHlV/ijvuzs7ISEhK5LYmJinnrqqb6LyCX+qM8xX4lE8tP0H1KpdPHixX0dkXP8VN+kSZNiYmIcfw8ePHjixIl9HZFz/FQfAGDBggVCoVAoFC5YsKCvY3FJt6+86iabxeiruem6khyXNSxmHI7jyXFZDRXmXvhGnhDv7mTBnrb7KIK+fEpdUWwQiHE2x3/rLAwkYTfryYRUcdazIR5u4pE+o446+nF99FCRcrKX34v3QwryVE0VxmdfjGJM1uGpvmOfNcjCeakTB747B7f/T61ptc5aFcG4JvNhWFdqMrST/znuAACjJsm0KqL+AfMJl1lfU41FkSTyUmD9hsHDRE3VFsbVmPVpVYQkpFcnr/cHJCFcTRvz1MvM+mga9I/ZbbwLBoAHs9IMzCZIr4H0QYH0QYH0QYH0QYH0QYH0QYH0QYH0QYH0QYH0QdF7+urqaiZMSissugmzk2dmTcg59IX3goKlH9S+mbPGt7R0O/NiVza99VpeXq73IvoZf9fX0NjDzItdKX9w30vhPIpPnnHR6rS7d+/MO5crkUjT0kav/t06mSyExWI5Moht+9PbeXm5ISHyp57MfvGF3zs2uXLl4g/n8+78WGgw6Icnj1y2dEVKyuO3Cwt+/+pqAMDCxTOeGDd+y+btGIuFYdiRfxzKy8ttam5ITxuzbt1GSaDE8SjMjg/fLb5zW6/XxQyOmz599jMz59I0PTE7HQCw7U9vF9y69sfX3/XuL/V+7SMIYsPGlwxG/Yc79qx98bXGxvoNG1/qTKPx14N705SjP9yxZ+6cRf84+tWlSxcc+T22bnuToqiNGza/9+5OuXzQ62+s0+l1o1LTt767EwBw+FDuls3bHekxTp46YjAY1qx55fUNW24UXPls94eOPa/f8GJrW8vW93b9/fCZMWOe3Lnr/YqKcgzDvj19CQCwYf3bXnfnk9p37fql0tJ7f/vyeGREFAAgPCzi2Im/azQ/5bAalZqePWkaACD18bQj/zhUVHzriSfG83i8v+z7SsAXSCRSAEBcbMKZb0+UlZWkp41+dO80LRSKlj//00zO0381+/iJv69/ddP165fv3btz8IsjCkUMAGD58yuvX7+Uc+jAW5u2ef0HdsX7+iorH4iEIoc7AEBSUkpSUgoAoL6+DgCQkvJzrjWhUESShONvk9G4f/+fi+/cVqtVjiXt//rj38CwjPSxnZ+SklK+OZKj0XTU1Fbx+XyHOwdDhiRdu37J67/uEbx/8BoM+gBn6XQc2Yu6prXBsJ+GSZubm/7n5RV2u/3NN7Z+l3ft9KmLLvdO0wLBz5PL8/kCAIBWq1G3q7oudxSZTL5KdNiJ92ufQCAwm7sX9w/n8yiK+sP6tx1pjNRO650DDLNYfh4/NJmMAACxOJDP4zv+7sRsNslknj4s0GO8X/uGDR1uMpnKH5Q6PtbUVK17ZWVdXY2bTYxGg0gk7kwBlX/ph86iRxIoYhhWUVHW+bG09B6PxwsOlg0dmmw2m6urKzuL7t+/GxsT772f5Rzv60tPHxMZGb1nz65Lly4U3Ly26+NtWq0mOnqwm01iYxNUqrbTZ46TJHnt2qWSkh9FIlFLazMAICIiCgBw/sK5+6X3HFfeisryo0cP2+32+6X3zn13esL4KTiOj858IiI88oMdW8rK77e3q/f95ZPyB6Xz5i1x5FKVyUJu3rpWVVXh9R/rfX1sNvuDP31KUuSbb726/g8vikWBW97Z7j4L56SJUxcvWv75gc8mTx194tSRtS++Nnny9C/+uueTT7crFDGTJk37/MBn+/f/GQBAELYF85cVFt2cNDnjtfVrRqWmr1q1zvGlWzbvEAqEq9c8t2TZrOI7t7e+uzNp2HDH/hcvXH79+uVDX3n/bo/5GZe8L1vCBgviRjLnPRpIVBbr22pNk5lyTPr7TZufg/RBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBwawPw4DfzXbQK2AeVC3mVaQhHH0H4Z2I+g/6dkIs4zCuxqwvJDKgudrnYy7+RlO1aVA0cxZ2Zn2Dhwoowl50od1LgfUDii+0Azsd40G+aI/eqNR3kMc/a5DIuWlTQsRBzFW6/6JTE7e+U+nUttkvRAolzMOQ3Xgd+kqu+n6Bji/E+aJemv3FTtMAAJbbcRIvYjaQZiOVlBE4ZroM53j0pd2eRUjVaLOaeuNlfADAqVOnAAAzZ87sna/rwcv43a5HIRG993YlJujAMCwygd9r39hdULMZCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCn/MTT5jxozGxkaapjunraNpOiIiwg9zk/tj7ZsxYwaO4ziOs/4Fm81+5pln+jouJ/ijvvnz50dFRXVdolAoFi5c2HcRucQf9QUHB0+bNq3zyMUwLDs7uzPXtl/hj/oAAPPmzYuOjnb8HRUVtWjRor6OyDl+qk8mk2VnZ2MYhmHYtGnTpFJpX0fkHD/V58hNrlAoIiMj/Tk3uRcaLkYtWVFs0KpJs56yGCmr1WstobbWNoABuVzurR0GBGA8IS4Q44EydsJIkSev27un5/oogr59XlNeqNepCWm4kB3Awbk4m4PjbP+t0RRpJwmKIijSRGhajIEy7rB00cgsqYev3v+SHuorv23IP9bGEXKDwgPFoYKefXefo2s1aZp0hNGWNVueOKonKZy7rc9qtuf+pVmrocISggVBTqb273cY280tFR2SYPyZleGcgO5Vw+7p07WTx/7cIJSLQ2L8sRUGQ1u1xtxhfHZ1RGBwN06I3dDXUmc5c6BFnigTBfnv3AwwGNSW1grVzBVh8ijm+YMceHqaN+mo0wdaIpJDB6o7AIBIxotIDs39vNmo83SmFY/0kQR97LOG0HhZgGiA53jnibjyeNmJPY0U6dFB6ZG+a2faBcEiUciArXddEcn4PIng+lmP5uxi1mfUUjUlpqDogXatcEOwQlp5x2TUkoxrMuv759E2SaSf3nL6DkmEJP+EmnE1Bn0Wo72+wiyW+2nDuEPT/OqbmSWl3s+IFRgqrC0xWowM1xAGfRXF+kA58zR2AxAMBA4SVt1lyO/IoO9BkVEY4qdVz9eIggUVRQzTZjK0sNseWuLHeq3D4xG0uraT3+6qffgjQViHPjZm8oQVIbIoAED+1a/P53/5u+WfHDy8obWtJjzssQlPLBs1cqpjq9t38vK+32uxGpOGZj2R+WvgmJ3WB/ClATU3XKc8A4Ch9pEETZK0j3pQKIrc88ULtQ9/nP/sH19d+xWfL/543287NM0AADaba7bojp/ZsWD2Hz/YfC15SNbXxzbrDe0AgKaWiq+OvJWZNmvDuiOpKVOOn/nQF7E5YHNxgnAk53OJOzVaFcEX+WqqzaqawjZV7aK5bycmZIhFwTOnrQvg8vOvfu0Y3CAI67RJqwZHp2AYpnz8aYoiGxrLAACXrn0THBQ58cnn+XxxYkJGxijfzozIE7C1KnezBrvTZ9CQ7ADcB1EBAEBN3R0uhxcfO8rxEcfxGMXImrpix6guAEARlewo4vFEAACL1QAAULfXDwqN7dxJVOQwAIDv5ubk8NkGjbvWn7tzH5uL+W4M3WI12gjLq29mdl0YJA0HAACa/mV+QIdTs1kvEgZ1LuSwAzqLfAFF0bjb+uNOn0CEU1bmlnfPEItkvADh8sUfdF3Ich8sADyeyEZYOj/aCPMvRXsR0koJAt3WMDdlfDHbZvHVLK/hYQkWqzFIGiYLjnQsUbXXB4oYknIGScPKK653Pr9RWn7Fp7WPMJMCsbv/qLtzH0/AYnNZhMUnFXBIQmZiQuY3J7ZqtC0GY0f+1a937X7+VvG37rcakTxJp1fl5n0CAHhQWXDt5nHgs4aLzURyeDiX504RQ7tPMVSgbzMFRwd6OzYAAFixbNfVgqNffv1G7cMfQ+UxmcpZY9Jnu98kaci4X0154VrBsX9ezgmShi+cs2n3gdV2u08OEb3KFDuc4Y6Lobe5sthw9aw2akSYt2PrB9QXN4+dIY1za5ChSRyVKNC2mm0mX11A/BabmdS1maMTGW5YGQ7eAD5riDKwuaojarjzWzeKIt/aNtVpEUna2DjXaassMjxx9W93u//qbvHme9m0i7QidjvFYjk5/Suiklc+/7GrHbZWtA9JD+RwGc6qzENFZgN1cEtNTFoEz0VPfXtHo9PlFovB0eL9JTjOkQR681baVQwAABth5XKcDP2w2dxAsfMLvUVvq73dtPytmAA+w9Hp0Uhb4YWO2+d1sekRLNx/nyDwFnbSXl3QmD5ZMiKLuZPYIx2PPymVR3Dq77b54ZO83oWm6Yd3WkIiOCnjPBqc8EgfxsJ+9dtwDk41lw3wpCdNpe1cLj39v8IxlkdtSU8PRjYHm70mApDWuqIWu2eDeP0LO0nXFbVgdtvsNZFsj58Y6t5DGhRJf/vX5pY6myI1jMPrpaQnvQBhIWtvN0fEBUxdNghnd+MepidPWN0813Hzh44QhSRYIWHhvZTKxUdQFN1eq1HX6dImB6VlB3mwxb/RwwfUOlqIwn9qqu8aBVIBXxogkvHZXF/1DPoC0kIZOswmrdXcYYpLEaaOl0rlPekYhnq6lCTomnum8iLjw/sGGmA8EYcr4LAD/PSgpmlA2UibibAYbRgNFEmix1KFCSOgxhG99laRQUNq2gitivBkcL5vwIAwkC0J4UjlHJHUO/9jf3wpqx8x8O8ifArSBwXSBwXSBwXSBwXSB8X/A86fhONOxhYmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Compile the Graph\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='3a371802-0fe0-44d8-b7c6-7a5d85c5dd46'), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--b5233fdd-2d5a-4c3c-9074-5ff00321cf09-0', usage_metadata={'input_tokens': 2, 'output_tokens': 10, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 27}})]}\n",
      "{'messages': [HumanMessage(content='I am learning state machines becasue I am learning LangGraph, can you help me it.', additional_kwargs={}, response_metadata={}, id='58e92d1c-be54-4bad-a7ec-def816f55f2b'), AIMessage(content='That\\'s an excellent connection to make! You\\'re absolutely right: **LangGraph is fundamentally a framework for building state machines.** Understanding state machines will give you a powerful mental model for designing robust and complex LangGraph applications.\\n\\nLet\\'s break it down.\\n\\n---\\n\\n## Part 1: What is a State Machine? (The Fundamentals)\\n\\nA **State Machine** (more formally, a Finite State Machine or FSM) is a mathematical model of computation. It\\'s a way to describe how a system behaves by defining:\\n\\n1.  **States:** A finite set of distinct conditions or modes that a system can be in at any given moment. (e.g., \"Idle,\" \"Processing,\" \"Error,\" \"Complete\").\\n2.  **Transitions:** The rules that dictate how the system moves from one state to another. A transition is triggered by an **event** and leads to a new state.\\n3.  **Events:** Inputs or occurrences that cause a state change. (e.g., \"User clicks button,\" \"Data received,\" \"API call failed\").\\n\\n**Think of a simple traffic light:**\\n\\n*   **States:** Red, Yellow, Green.\\n*   **Events:** Timer expires.\\n*   **Transitions:**\\n    *   From Green, on \"timer expires,\" go to Yellow.\\n    *   From Yellow, on \"timer expires,\" go to Red.\\n    *   From Red, on \"timer expires,\" go to Green.\\n\\n**Why are they useful?**\\n\\n*   **Predictability:** You always know what state the system is in and what states it can transition to.\\n*   **Control:** Explicitly define all possible paths and behaviors.\\n*   **Error Handling:** Define specific error states and how to recover or report issues.\\n*   **Debugging:** Easier to trace the flow of logic.\\n*   **Complexity Management:** Break down complex processes into manageable, discrete steps.\\n\\n---\\n\\n## Part 2: How LangGraph *Is* a State Machine\\n\\nLangGraph directly implements the concepts of state machines to orchestrate LLM calls and other computational steps.\\n\\nLet\\'s map the concepts:\\n\\n1.  **Nodes = States:**\\n    *   In LangGraph, each `node` you define in your graph (`graph.add_node(\"my_node\", my_function)`) represents a distinct **state** or step in your process.\\n    *   When the graph executes, it enters a node, the associated function runs, and then the graph transitions out of that node.\\n\\n2.  **Edges = Transitions:**\\n    *   `graph.add_edge(\"node_A\", \"node_B\")`: This is an **unconditional transition**. After `node_A` finishes, the graph *always* moves to `node_B`.\\n    *   `graph.add_conditional_edges(\"node_A\", should_continue_function, {\"option1\": \"node_B\", \"option2\": \"node_C\"})`: This is a **conditional transition**.\\n        *   `should_continue_function` acts as the **event handler** or **decision logic**. It inspects the current `GraphState` (the machine\\'s data) and returns a string indicating which path to take.\\n        *   The mapping `{\"option1\": \"node_B\", \"option2\": \"node_C\"}` defines the possible **next states** based on the `should_continue_function`\\'s output.\\n\\n3.  **Graph State = The Machine\\'s Data:**\\n    *   The `GraphState` (which you define using `TypedDict` or similar) is the central piece of data that represents the *current condition* of your state machine.\\n    *   Nodes read from and write to this state.\\n    *   Conditional edges use this state to make transition decisions.\\n\\n4.  **Entry Point (`set_entry_point`) = Initial State:**\\n    *   This defines where your state machine starts its execution.\\n\\n5.  **Finish Edges (`add_finish_edge`) = Terminal States:**\\n    *   These define states from which the graph can exit, indicating the completion of a process or a specific outcome.\\n\\n**In essence, when you build a LangGraph, you are designing a custom state machine tailored to your LLM application\\'s needs.**\\n\\n---\\n\\n## Part 3: Why State Machines are Crucial for LangGraph (Benefits for LLM Apps)\\n\\nThe state machine paradigm is incredibly powerful for LLM applications because they often involve:\\n\\n1.  **Multi-step Reasoning:** LLMs rarely solve complex problems in one go. They need to plan, execute, reflect, and revise. State machines provide the structure for this.\\n2.  **Dynamic Control Flow:** The path an LLM application takes often depends on the LLM\\'s output, user input, or external tool results. Conditional transitions handle this naturally.\\n3.  **Error Handling and Recovery:** LLM calls can fail (API errors), hallucinate, or produce invalid outputs. You can define specific \"Error\" states and transitions to retry, ask for clarification, or notify a human.\\n4.  **Human-in-the-Loop:** You can design states where the process pauses, waits for human input/review, and then transitions based on that input.\\n5.  **Persistence and Re-entrancy:** Because the state is explicit, you can save the `GraphState` at any point and resume execution later, even across different sessions or deployments.\\n6.  **Observability and Debugging:** By visualizing your graph, you can clearly see the intended flow and trace the actual execution path, making debugging much easier than with linear scripts.\\n7.  **Agentic Behavior:** LangGraph is often used to build \"agents.\" An agent is essentially a state machine that observes, thinks (LLM call), acts (tool call), and then transitions to a new state based on the outcome.\\n\\n---\\n\\n## Part 4: Practical Example (Conceptual)\\n\\nLet\\'s imagine a simple \"Research and Report Generation\" LangGraph application.\\n\\n**States (Nodes):**\\n\\n1.  `plan_research`: LLM generates a research plan.\\n2.  `execute_research`: Uses tools (e.g., search engine) to gather data based on the plan.\\n3.  `draft_report`: LLM drafts the report based on research data.\\n4.  `review_report`: LLM reviews the draft for quality, completeness, and accuracy.\\n5.  `revise_report`: LLM revises the report based on review feedback.\\n6.  `finalize_report`: Final formatting and output.\\n\\n**Graph State (Simplified):**\\n\\n```python\\nfrom typing import TypedDict, List, Dict\\n\\nclass GraphState(TypedDict):\\n    topic: str\\n    research_plan: str\\n    research_data: List[str]\\n    draft: str\\n    review_feedback: str\\n    final_report: str\\n    iterations: int # To prevent infinite loops\\n```\\n\\n**Transitions (Edges):**\\n\\n*   `plan_research` -> `execute_research` (unconditional, once plan is made)\\n*   `execute_research` -> `draft_report` (unconditional, once research is done)\\n*   `draft_report` -> `review_report` (unconditional, once draft is made)\\n*   `review_report` -> **Conditional Edge**:\\n    *   If `review_feedback` indicates revisions are needed, go to `revise_report`.\\n    *   If `review_feedback` indicates it\\'s good, go to `finalize_report`.\\n*   `revise_report` -> `review_report` (after revision, always re-review)\\n*   `finalize_report` -> `FINISH` (terminal state)\\n\\n**Conceptual LangGraph Structure:**\\n\\n```python\\nfrom langgraph.graph import StateGraph, END\\n\\n# Define your nodes (functions that represent states)\\ndef plan_research_node(state: GraphState) -> GraphState:\\n    # LLM call to generate plan\\n    print(\"Planning research...\")\\n    state[\"research_plan\"] = \"...\" # LLM output\\n    return state\\n\\ndef execute_research_node(state: GraphState) -> GraphState:\\n    # Tool calls to gather data\\n    print(\"Executing research...\")\\n    state[\"research_data\"] = [\"...\", \"...\"] # Tool output\\n    return state\\n\\ndef draft_report_node(state: GraphState) -> GraphState:\\n    # LLM call to draft report\\n    print(\"Drafting report...\")\\n    state[\"draft\"] = \"...\" # LLM output\\n    return state\\n\\ndef review_report_node(state: GraphState) -> GraphState:\\n    # LLM call to review draft\\n    print(\"Reviewing report...\")\\n    state[\"review_feedback\"] = \"Needs more detail on X.\" # LLM output\\n    state[\"iterations\"] += 1\\n    return state\\n\\ndef revise_report_node(state: GraphState) -> GraphState:\\n    # LLM call to revise based on feedback\\n    print(\"Revising report...\")\\n    state[\"draft\"] = \"...\" # LLM output\\n    return state\\n\\n# This is your conditional transition logic\\ndef should_continue_review(state: GraphState) -> str:\\n    if \"Needs\" in state[\"review_feedback\"] and state[\"iterations\"] < 3:\\n        print(\"Review indicates revisions needed.\")\\n        return \"revisions_needed\"\\n    else:\\n        print(\"Review complete or max iterations reached.\")\\n        return \"done_reviewing\"\\n\\n# Build the graph\\nworkflow = StateGraph(GraphState)\\n\\nworkflow.add_node(\"plan_research\", plan_research_node)\\nworkflow.add_node(\"execute_research\", execute_research_node)\\nworkflow.add_node(\"draft_report\", draft_report_node)\\nworkflow.add_node(\"review_report\", review_report_node)\\nworkflow.add_node(\"revise_report\", revise_report_node)\\nworkflow.add_node(\"finalize_report\", lambda state: (print(\"Finalizing report...\"), state)) # Simple node\\n\\nworkflow.set_entry_point(\"plan_research\")\\n\\nworkflow.add_edge(\"plan_research\", \"execute_research\")\\nworkflow.add_edge(\"execute_research\", \"draft_report\")\\nworkflow.add_edge(\"draft_report\", \"review_report\")\\n\\n# Conditional edge from review_report\\nworkflow.add_conditional_edges(\\n    \"review_report\",\\n    should_continue_review,\\n    {\\n        \"revisions_needed\": \"revise_report\",\\n        \"done_reviewing\": \"finalize_report\",\\n    }\\n)\\n\\nworkflow.add_edge(\"revise_report\", \"review_report\") # Always re-review after revision\\nworkflow.add_edge(\"finalize_report\", END) # End the graph\\n\\napp = workflow.compile()\\n\\n# To run it:\\n# initial_state = GraphState(topic=\"AI in healthcare\", research_plan=\"\", research_data=[], draft=\"\", review_feedback=\"\", final_report=\"\", iterations=0)\\n# for s in app.stream(initial_state):\\n#     print(s)\\n```\\n\\n---\\n\\n## Part 5: Key Takeaways for Learning LangGraph with State Machines\\n\\n1.  **Visualize Your Graph:** Before writing code, draw your state machine. Boxes for states (nodes), arrows for transitions (edges). Label the arrows with the conditions that trigger them.\\n2.  **Define Your `GraphState` First:** This is the \"memory\" of your state machine. Think about all the data your nodes will need to read and write.\\n3.  **Nodes are Pure Functions (Ideally):** Each node should take the `GraphState` as input, perform its specific task (e.g., make an LLM call, use a tool), update the `GraphState` with its results, and return the modified `GraphState`.\\n4.  **Conditional Edges are Your Decision Makers:** These are where the \"intelligence\" of your state machine often lies. The function associated with `add_conditional_edges` should inspect the `GraphState` and return a string that maps to a specific next node.\\n5.  **Think About Loops and Termination:** How do you prevent infinite loops (e.g., `review` -> `revise` -> `review` forever)? Add counters to your `GraphState` or specific conditions to break out. How does the process ultimately finish? Use `END`.\\n6.  **Error States:** Consider adding explicit \"Error\" nodes and transitions to them if a previous node fails. This makes your graph more resilient.\\n\\nBy approaching LangGraph with a state machine mindset, you\\'ll build more structured, understandable, and powerful LLM applications. Good luck!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--c446a19a-4770-4606-9d74-3a3bfa2c4756-0', usage_metadata={'input_tokens': 21, 'output_tokens': 2772, 'total_tokens': 4143, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1350}})]}\n"
     ]
    }
   ],
   "source": [
    "def chat(user_input: str, history):\n",
    "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(result)\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db71d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
